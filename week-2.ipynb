{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14634106,"sourceType":"datasetVersion","datasetId":9348068}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-27T03:55:52.687565Z","iopub.execute_input":"2026-01-27T03:55:52.687874Z","iopub.status.idle":"2026-01-27T03:55:54.528844Z","shell.execute_reply.started":"2026-01-27T03:55:52.687838Z","shell.execute_reply":"2026-01-27T03:55:54.527794Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"simple or","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef or_(x1, x2):\n    w1 = 1\n    w2 = 1\n    bias = -0.5\n    activation = x1*w1+x2*w2+bias\n    if activation > 0:\n        return 1\n    else:\n        return 0\nprint(or_(1, 0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:02:16.300383Z","iopub.execute_input":"2026-01-27T04:02:16.301025Z","iopub.status.idle":"2026-01-27T04:02:16.306559Z","shell.execute_reply.started":"2026-01-27T04:02:16.300953Z","shell.execute_reply":"2026-01-27T04:02:16.305439Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"or gate using single perceptron","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef step(x):\n    return 1 if x >= 0 else 0\nclass Perceptron:\n    def __init__(self, w, b):\n        self.w = w\n        self.b = b\n    def predict(self, inputs):\n        total = np.dot(self.w, inputs) + self.b\n        return step(total)\nw = np.array([1, 1])\nb = -0.5\nor_ = Perceptron(w, b)\nfor x in ([[0, 0], [0, 1], [1, 0], [1, 1]]):\n    print (x, or_.predict(np.array(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:08:31.546674Z","iopub.execute_input":"2026-01-27T04:08:31.546985Z","iopub.status.idle":"2026-01-27T04:08:31.555427Z","shell.execute_reply.started":"2026-01-27T04:08:31.546949Z","shell.execute_reply":"2026-01-27T04:08:31.554184Z"}},"outputs":[{"name":"stdout","text":"[0, 0] 0\n[0, 1] 1\n[1, 0] 1\n[1, 1] 1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"simple and","metadata":{}},{"cell_type":"code","source":"def and_(x1, x2):\n    w1 = 1\n    w2 = 1\n    bias = -1.5\n    act = x1*w1+x2*w2+bias\n    if act > 0:\n        return 1\n    else:\n        return 0\nprint(and_(1, 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:09:37.026620Z","iopub.execute_input":"2026-01-27T04:09:37.027715Z","iopub.status.idle":"2026-01-27T04:09:37.033075Z","shell.execute_reply.started":"2026-01-27T04:09:37.027678Z","shell.execute_reply":"2026-01-27T04:09:37.032131Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"and using single perceptron","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef step(x):\n    return 1 if x>= 0 else 0\nclass Perceptron:\n    def __init__(self, w, b):\n        self.w = w\n        self.b = b\n    def predict(self, inputs):\n        total = np.dot(self.w, inputs) + self.b\n        return step(total)\nw = np.array([1, 1])\nb = -1.5\nand_ = Perceptron(w, b)\nfor x in np.array([[0, 0], [0, 1], [1, 0], [1, 1]]):\n    print(x, and_.predict(np.array(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:13:51.557780Z","iopub.execute_input":"2026-01-27T04:13:51.558117Z","iopub.status.idle":"2026-01-27T04:13:51.566654Z","shell.execute_reply.started":"2026-01-27T04:13:51.558093Z","shell.execute_reply":"2026-01-27T04:13:51.565781Z"}},"outputs":[{"name":"stdout","text":"[0 0] 0\n[0 1] 0\n[1 0] 0\n[1 1] 1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"implementing the XOR operation (Non linear data) using a single perceptron","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef step(x):\n    return 1 if x>= 0 else 0\nclass Perceptron:\n    def __init__(self, w, b):\n        self.w = w\n        self.b = b\n    def predict(self, inputs):\n        total = np.dot(self.w, inputs)+self.b\n        return step(total)\nw = np.array([1, 1])\nb = -0.5\nxor_ = Perceptron(w, b)\nfor x in ([[0, 0], [0, 1], [1, 0], [1, 1]]):\n    print(x, xor_.predict(np.array(x)))\n#for xor function we can't draw a line(non-linear data) and separate. This can be achieved by combining perceptrons","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:18:29.275824Z","iopub.execute_input":"2026-01-27T04:18:29.276247Z","iopub.status.idle":"2026-01-27T04:18:29.287281Z","shell.execute_reply.started":"2026-01-27T04:18:29.276171Z","shell.execute_reply":"2026-01-27T04:18:29.286295Z"}},"outputs":[{"name":"stdout","text":"[0, 0] 0\n[0, 1] 1\n[1, 0] 1\n[1, 1] 1\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"XOR logic operation using a multi-perceptron network","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef and_(x1, x2):\n    w1 = 1\n    w2 = 1\n    b = -1.5\n    act = x1*w1+x2*w2+b\n    if act > 0:\n        return 1\n    else:\n        return 0\ndef nand_(x1, x2):\n    w1 = -1\n    w2 = -1\n    b = 1.5\n    act = x1*w1+x2*w2+b\n    if act >= 0:\n        return 1\n    else:\n        return 0\ndef or_(x1, x2):\n    w1 = 1\n    w2 = 1\n    b = -0.5\n    act = x1*w1+x2*w2+b\n    if act > 0:\n        return 1\n    else:\n        return 0\ndef xor_(x1, x2):\n    first_layer = nand_(x1, x2)\n    second_layer = or_(x1, x2)\n    output = and_(first_layer, second_layer)\n    return output\nprint(xor_(0, 0))\nprint(xor_(0, 1))\nprint(xor_(1, 0))\nprint(xor_(1, 1))\n#multiple layers help solve complex problems, they try with every non-linear mapping between inputs and output generating the correct answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:31:45.033465Z","iopub.execute_input":"2026-01-27T04:31:45.034364Z","iopub.status.idle":"2026-01-27T04:31:45.042423Z","shell.execute_reply.started":"2026-01-27T04:31:45.034330Z","shell.execute_reply":"2026-01-27T04:31:45.041364Z"}},"outputs":[{"name":"stdout","text":"0\n1\n1\n0\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"(¬XOR) logic operation using a multi-perceptron network","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef and_(x1, x2):\n    w1 = 1\n    w2 = 1\n    b = -1.5\n    act = x1*w1+x2*w2+b\n    if act > 0:\n        return 1\n    else:\n        return 0\ndef or_(x1, x2):\n    w1 = 1\n    w2 = 1\n    b = -0.5\n    act = x1*w1+x2*w2+b\n    if act > 0:\n        return 1\n    else:\n        return 0\ndef nor_(x1, x2):\n    w1 = -1\n    w2 = -1\n    bias = 0.5\n    activation = x1*w1+x2*w2+bias\n    if activation > 0:\n        return 1\n    else:\n        return 0\ndef nxor_(x1, x2):\n    first_layer = nor_(x1, x2)\n    second_layer = and_(x1, x2)\n    output = or_(first_layer, second_layer)\n    return output\nprint(nxor_(0, 0))\nprint(nxor_(0, 1))\nprint(nxor_(1, 0))\nprint(nxor_(1, 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:40:40.436926Z","iopub.execute_input":"2026-01-27T04:40:40.437289Z","iopub.status.idle":"2026-01-27T04:40:40.446253Z","shell.execute_reply.started":"2026-01-27T04:40:40.437260Z","shell.execute_reply":"2026-01-27T04:40:40.445182Z"}},"outputs":[{"name":"stdout","text":"1\n0\n0\n1\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"Demonstrate that the thresholding logic used by perceptron is very harsh.","metadata":{}},{"cell_type":"code","source":"def perceptron(x, w=1, b=0):\n    net = w * x + b\n    return 1 if net >= 0 else 0\n\ninputs = [-0.01, -0.001, 0, 0.001, 0.01]\n\nfor x in inputs:\n    print(f\"x = {x:>6}, output = {perceptron(x)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:22:33.228586Z","iopub.execute_input":"2026-02-02T17:22:33.229023Z","iopub.status.idle":"2026-02-02T17:22:33.241701Z","shell.execute_reply.started":"2026-02-02T17:22:33.228952Z","shell.execute_reply":"2026-02-02T17:22:33.240591Z"}},"outputs":[{"name":"stdout","text":"x =  -0.01, output = 0\nx = -0.001, output = 0\nx =      0, output = 1\nx =  0.001, output = 1\nx =   0.01, output = 1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\n\ndef step(x):\n    return 1 if x>= 0 else 0\nclass Perceptron:\n    def __init__(self, w, b):\n        self.w = w\n        self.b = b\n    def predict(self, inputs):\n        total = np.dot(self.w, inputs)+self.b\n        return step(total)\nw = np.array([1, 1])\nb = -0.5\nobj = Perceptron(w, b)\nx = np.array([1, 1])\nprint(obj.predict(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:47:54.403310Z","iopub.execute_input":"2026-01-27T04:47:54.404043Z","iopub.status.idle":"2026-01-27T04:47:54.411115Z","shell.execute_reply.started":"2026-01-27T04:47:54.403996Z","shell.execute_reply":"2026-01-27T04:47:54.410195Z"}},"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndf = pd.read_excel('/kaggle/input/movies123/movies.xlsx')\nX = df[['f1', 'f2', 'f3', 'f4']].values\ny = df['out'].values\nw1 = 1\nw2 = 1\nw3 = 1\nw4 = 1\nb = -0.5\nthreshold = 2\nfor i in range(len(X)):\n    output = X[i][0]*w1+X[i][1]*w2+X[i][2]*w3+X[i][3]*w4+b\n    if output >= threshold:\n        print(\"like\")\n    else:\n        print(\"dislike\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:27:42.432901Z","iopub.execute_input":"2026-02-02T17:27:42.433375Z","iopub.status.idle":"2026-02-02T17:27:42.570842Z","shell.execute_reply.started":"2026-02-02T17:27:42.433339Z","shell.execute_reply":"2026-02-02T17:27:42.569645Z"}},"outputs":[{"name":"stdout","text":"dislike\nlike\nlike\ndislike\nlike\ndislike\nlike\ndislike\nlike\nlike\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def mp_perceptron(x, threshold=2):\n    s = np.sum(x)\n    return 1 if s >= threshold else 0\n\nfor i in range(len(X)):\n    print(mp_perceptron(X[i]), y[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:27:46.325060Z","iopub.execute_input":"2026-02-02T17:27:46.325464Z","iopub.status.idle":"2026-02-02T17:27:46.332300Z","shell.execute_reply.started":"2026-02-02T17:27:46.325429Z","shell.execute_reply":"2026-02-02T17:27:46.331039Z"}},"outputs":[{"name":"stdout","text":"0 0\n1 1\n1 1\n0 0\n1 1\n0 0\n1 1\n0 0\n1 1\n1 1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"w = np.ones(4)   # [1,1,1,1]\n\ndef perceptron_no_bias(x, w):\n    net = np.dot(x, w)\n    return 1 if net >= 0 else 0\n\nfor i in range(len(X)):\n    print(perceptron_no_bias(X[i], w), y[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:28:49.544181Z","iopub.execute_input":"2026-02-02T17:28:49.545350Z","iopub.status.idle":"2026-02-02T17:28:49.552090Z","shell.execute_reply.started":"2026-02-02T17:28:49.545299Z","shell.execute_reply":"2026-02-02T17:28:49.550817Z"}},"outputs":[{"name":"stdout","text":"1 0\n1 1\n1 1\n1 0\n1 1\n1 0\n1 1\n1 0\n1 1\n1 1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"w = np.zeros(4)\nb = 0\nlr = 0.1\nepochs = 10\n\nfor epoch in range(epochs):\n    errors = 0\n    for i in range(len(X)):\n        net = np.dot(X[i], w) + b\n        y_pred = 1 if net >= 0 else 0\n\n        error = y[i] - y_pred\n        if error != 0:\n            w = w + lr * error * X[i]\n            b = b + lr * error\n            errors += 1\n\n    print(f\"Epoch {epoch+1}, Errors: {errors}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:32:11.478258Z","iopub.execute_input":"2026-02-02T17:32:11.479473Z","iopub.status.idle":"2026-02-02T17:32:11.488675Z","shell.execute_reply.started":"2026-02-02T17:32:11.479425Z","shell.execute_reply":"2026-02-02T17:32:11.487568Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Errors: 5\nEpoch 2, Errors: 3\nEpoch 3, Errors: 0\nEpoch 4, Errors: 0\nEpoch 5, Errors: 0\nEpoch 6, Errors: 0\nEpoch 7, Errors: 0\nEpoch 8, Errors: 0\nEpoch 9, Errors: 0\nEpoch 10, Errors: 0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\n\nX = np.array([\n    [0,0],\n    [0,1],\n    [1,0],\n    [1,1]\n])\nfunctions = [\n    [0,0,0,0],  # f1\n    [0,0,0,1],  # f2 (AND)\n    [0,0,1,0],\n    [0,0,1,1],\n    [0,1,0,0],\n    [0,1,0,1],\n    [0,1,1,0],  # XOR ❌\n    [0,1,1,1],  # OR\n    [1,0,0,0],\n    [1,0,0,1],\n    [1,0,1,0],  # XNOR ❌\n    [1,0,1,1],\n    [1,1,0,0],\n    [1,1,0,1],\n    [1,1,1,0],\n    [1,1,1,1]\n]\ndef perceptron_learn(X, y, epochs=20):\n    w = np.zeros(2)\n    b = 0\n    for _ in range(epochs):\n        for i in range(len(X)):\n            y_pred = 1 if np.dot(X[i], w) + b >= 0 else 0\n            w += (y[i] - y_pred) * X[i]\n            b += (y[i] - y_pred)\n    preds = [(1 if np.dot(X[i], w) + b >= 0 else 0) for i in range(4)]\n    return preds == y\nnot_learned = 0\n\nfor i, f in enumerate(functions):\n    if not perceptron_learn(X, f):\n        not_learned += 1\n        print(f\"f{i+1} NOT learned\")\n\nprint(\"Total not learned:\", not_learned)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:46:06.519870Z","iopub.execute_input":"2026-02-02T17:46:06.520830Z","iopub.status.idle":"2026-02-02T17:46:06.545168Z","shell.execute_reply.started":"2026-02-02T17:46:06.520783Z","shell.execute_reply":"2026-02-02T17:46:06.543776Z"}},"outputs":[{"name":"stdout","text":"f7 NOT learned\nf10 NOT learned\nTotal not learned: 2\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def xor_mlp(x):\n    # Hidden layer\n    h1 = 1 if (x[0] == 1 and x[1] == 0) else 0\n    h2 = 1 if (x[0] == 0 and x[1] == 1) else 0\n        # Output layer\n    out = 1 if (h1 + h2) == 1 else 0\n    return out\n\nfor x in X:\n    print(x, xor_mlp(x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:48:51.190116Z","iopub.execute_input":"2026-02-02T17:48:51.190556Z","iopub.status.idle":"2026-02-02T17:48:51.198077Z","shell.execute_reply.started":"2026-02-02T17:48:51.190520Z","shell.execute_reply":"2026-02-02T17:48:51.197098Z"}},"outputs":[{"name":"stdout","text":"[0 0] 0\n[0 1] 1\n[1 0] 1\n[1 1] 0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Multi-Layer Perceptron for ALL Boolean functions (2 inputs)\n\n# Step activation\ndef step(z):\n    return 1 if z >= 0 else 0\n\n\n# MLP architecture:\n# 2 inputs -> 4 hidden perceptrons (one per input pattern) -> 1 output perceptron\ndef mlp_boolean(x, w_out):\n    x1, x2 = x\n\n    # ---------- Hidden layer ----------\n    # Each neuron fires for exactly ONE input combination\n    h1 = step(-x1 - x2 - 0.5)      # fires for (0,0)\n    h2 = step(-x1 + x2 - 0.5)      # fires for (0,1)\n    h3 = step( x1 - x2 - 0.5)      # fires for (1,0)\n    h4 = step( x1 + x2 - 1.5)      # fires for (1,1)\n\n    # ---------- Output layer ----------\n    # Output weights encode the truth table\n    y = step(\n        w_out[0]*h1 +\n        w_out[1]*h2 +\n        w_out[2]*h3 +\n        w_out[3]*h4 - 0.5\n    )\n\n    return y\n\n\n# ---------- All possible inputs ----------\nX = [(0,0), (0,1), (1,0), (1,1)]\n\n\n# ---------- Boolean functions ----------\n# Truth tables ordered as: (0,0), (0,1), (1,0), (1,1)\nboolean_functions = {\n    \"ZERO\"  : [0,0,0,0],\n    \"AND\"   : [0,0,0,1],\n    \"OR\"    : [0,1,1,1],\n    \"XOR\"   : [0,1,1,0],\n    \"XNOR\"  : [1,0,0,1],\n    \"NAND\"  : [1,1,1,0],\n    \"NOR\"   : [1,0,0,0],\n    \"ONE\"   : [1,1,1,1]\n}\n\n\n# ---------- Test all Boolean functions ----------\nfor name, w_out in boolean_functions.items():\n    print(f\"\\n{name}\")\n    for x in X:\n        print(x, \"->\", mlp_boolean(x, w_out))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:55:44.474636Z","iopub.execute_input":"2026-02-02T17:55:44.475146Z","iopub.status.idle":"2026-02-02T17:55:44.486261Z","shell.execute_reply.started":"2026-02-02T17:55:44.475113Z","shell.execute_reply":"2026-02-02T17:55:44.485111Z"}},"outputs":[{"name":"stdout","text":"\nZERO\n(0, 0) -> 0\n(0, 1) -> 0\n(1, 0) -> 0\n(1, 1) -> 0\n\nAND\n(0, 0) -> 0\n(0, 1) -> 0\n(1, 0) -> 0\n(1, 1) -> 1\n\nOR\n(0, 0) -> 0\n(0, 1) -> 1\n(1, 0) -> 1\n(1, 1) -> 1\n\nXOR\n(0, 0) -> 0\n(0, 1) -> 1\n(1, 0) -> 1\n(1, 1) -> 0\n\nXNOR\n(0, 0) -> 0\n(0, 1) -> 0\n(1, 0) -> 0\n(1, 1) -> 1\n\nNAND\n(0, 0) -> 0\n(0, 1) -> 1\n(1, 0) -> 1\n(1, 1) -> 0\n\nNOR\n(0, 0) -> 0\n(0, 1) -> 0\n(1, 0) -> 0\n(1, 1) -> 0\n\nONE\n(0, 0) -> 0\n(0, 1) -> 1\n(1, 0) -> 1\n(1, 1) -> 1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Step function\ndef step(z): \n    return 1 if z >= 0 else 0\n\n# MLP: 3 inputs -> 8 hidden -> 1 output\ndef mlp_3bit(x, w):\n    x1,x2,x3 = x\n    \n    H = [\n        step(-x1-x2-x3-0.5),   # 000\n        step(-x1-x2+x3-0.5),   # 001\n        step(-x1+x2-x3-0.5),   # 010\n        step(-x1+x2+x3-1.5),   # 011\n        step(x1-x2-x3-0.5),    # 100\n        step(x1-x2+x3-1.5),    # 101\n        step(x1+x2-x3-1.5),    # 110\n        step(x1+x2+x3-2.5)     # 111\n    ]\n    \n    return step(sum(w[i]*H[i] for i in range(8)) - 0.5)\nX = [\n    (0,0,0),(0,0,1),(0,1,0),(0,1,1),\n    (1,0,0),(1,0,1),(1,1,0),(1,1,1)\n]\nw_and = [0,0,0,0,0,0,0,1]\nfor x in X:\n    print(x, mlp_3bit(x, w_and))\nw_or = [0,1,1,1,1,1,1,1]\nw_xor = [0,1,1,0,1,0,0,1]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T17:59:52.627389Z","iopub.execute_input":"2026-02-02T17:59:52.628438Z","iopub.status.idle":"2026-02-02T17:59:52.638961Z","shell.execute_reply.started":"2026-02-02T17:59:52.628395Z","shell.execute_reply":"2026-02-02T17:59:52.638102Z"}},"outputs":[{"name":"stdout","text":"(0, 0, 0) 0\n(0, 0, 1) 0\n(0, 1, 0) 0\n(0, 1, 1) 0\n(1, 0, 0) 0\n(1, 0, 1) 0\n(1, 1, 0) 0\n(1, 1, 1) 1\n","output_type":"stream"}],"execution_count":13}]}